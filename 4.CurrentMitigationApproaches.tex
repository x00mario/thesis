\epigraph{In theory, one can build provably secure systems. In theory, theory can be applied to practice but in practice, it can't.}%
{\textsc{M. Dacier, Eurecom Institute}}

This chapter will provide an in-depth overview of both former and current mitigation approaches aimed at protecting modern web applications and online documents from scripting attacks. We will shed light on the methodologies and technical implementations behind those mitigation techniques and security libraries, and later dedicate on documenting our efforts to break their protective effect and deliver rationale for a novel defense approach. Ultimately, we will conclude in deriving the general flaws existing in the described and widely used security tools and libraries and lead over to a proposal for a novel and DOM-based scripting attack protection model.

\section{Web Security, Mitigation and Defense}
\label{sec:4.current_mitigation_approaches}

   In this section, our primarily focus is placed on introducing and describing the defense tools and best practices to providing deeper understanding for the following Section~\ref{sec:5.attacking_existing_mitigation_approaches}. There, we shed light on design and implementation flaws of those techniques and illustrate the bypasses and attacks we discovered during our research. This section is essentially divided into two major parts. Server-side defense and mitigation techniques constitute the first and client-side protection mechanisms the latter. The second part will contain known as well as novel sand-boxing systems that we have successfully attacked. It can be argued that we have thereby created further empirical proof for the necessity of a novel web application defense approach.

  \subsection{History and Overview}
  \label{subsec:4.1.cma_history_and_overview}

  Scripting attacks targeted against web applications have a long history -- Guninski et al. reported some of the first incidents in 1999~\footnote{Guninski, G. et al., \textit{Hotmail security vulnerability - injecting JavaScript using <STYLE> tag}, \url{http://seclists.org/bugtraq/1999/Sep/261} (Sept 1999)} and a first comprehensive article on XSS attacks was issued by the CERT in early 2000~\footnote{CERT, \textit{Advisory CA-2000-02 Malicious HTML Tags Embedded in Client Web Requests}, \url{http://www.cert.org/advisories/CA-2000-02.html} (Feb 2000)}. From then on, both attacks and defense against have evolved dramatically. Simple attacks mitigated by naive filters and user input string replacements have been overtaken by complex scripting attacks. Those make use of modern browser features as well as legacy code to bypass sophisticated DOM tokenizer engines, CSS sanitizers and even the full stack JavaScript rewriting engines and sandboxes. User agents have added their share by implementing XSS filters, as 
well as both detection and prevention engines designed to mitigate impact and spread of XSS attacks and other script-based vectors. Having received rather limited attention from the security community early on, the focus on scripting attacks reached its peak in 2005 due to Samy Kamkar's deployment of an XSS worm against the \textit{MySpace} social network. His actions led to major penalties, as he compromised millions of user accounts and effectively left the whole website unusable for several days~\footnote{Kamkar, S., \textit{Technical explanation of The MySpace Worm}, \url{http://namb.la/popular/tech.html}, (April 2009)}. \\

  After the ``Samy Worm'' incident, attacks and defense mechanisms gained momentum among the community members, succeedingly bringing consequent development and complexity. First HTML sanitizing libraries have been already released in the year 2000, as the discussion on the origin of XSS attacks on the \textit{sla.ckers} forum indicates~\footnote{Hansen, R. et al, \textit{First XSS ?}, \url{http://sla.ckers.org/forum/read.php?2,130} (Aug 2006)}. The arms race initiated by prototypic attack vectors in the late nineties and climaxing in the ``Samy Worm'' incident continues until today. No definite cure against XSS attacks has been developed thus far. On top of its heavy impact on usability of modern web applications, even script deactivation does not fully solve the problems caused by scripting attacks. An urgent need for a novel approach of tackling scripting attack problem is obvious. For the purpose of facilitating a full comprehension of the evolution of attacks and their countermeasures, the following 
sections will describe the existing mitigation techniques installed on server- and client-side application layers. Afterwards, we will be properly prepared to dive into the complex world of attacking and bypassing the offense techniques in question, further underlining our motivation and rationale for a fresh and state-of-the-art approach.

  \subsection{Server Side Protection}
  \label{subsec:4.3.server_side_filtering}

    Server-side filtering and protection are the most prominent and widespread ways for web applications to defend against script injections and similar attacks. Depending on the context and later use for the user-provided data, a developer can chose from a set of four basic treatment categories, which are blocking, stripping and replacement, escaping and encoding, and, last but not least code rewriting. Modern web applications often employ at least one of those techniques while attempting to harden their code-base against external attacks. We will briefly discuss these aforementioned techniques to lay grounds for understanding their appropriate counteracting bypasses presented later in Section~\ref{sec:5.attacking_existing_mitigation_approaches}.

    \subsubsection{Blocking}
    \label{subsubsec:4.3.1.blocking}

    The most rigid way of dealing with unsolicited content is to straightforwardly block further processing upon detection and optionally display alternative content. Many web applications, server software, run-times and validation libraries do so in case an attacker supplies content that is out of bounds or indicates an attack attempt. Blocking can have many facets, ranging from denying reset of a password in case it does not comply with a given policy, neglecting acceptance of invalid date ranges, or showing warning pages when invalid or potentially dangerous characters and substrings are submitted to the application. Block invalid or incomplete POST requests, which can be considered an effective way of protecting against Cross Site Request Forgery (CSRF) and Request Body Extension (RBE) attacks is practiced by some web application frameworks such as CakePHP~\footnote{CakePHP Cookbook, \textit{Security}, \url{http://book.cakephp.org/2.0/en/core-libraries/components/security-component.html} (Jan 2012)}. 
POST requests missing a valid request hash can neither be processed by the application, nor is an attacker capable of extending or reducing the POST body fields to conduct attacks against the application. The result for an invalid POST request is an empty response body -- the framework will not process the request and it will not delegate it to controller and model methods. Internet Explorer's XSS filter and other comparable client-side tools perform similar blocking operations if invalid or potentially dangerous character data is submitted via URL. We will elaborate on this case in Section~\ref{subsec:4.4.client_side_filtering}. Web server software, like the Apache server and similar tools, perform blocking operations as well; for instance if a request header is too long or the cookie headers exceed the allowed length. Same goes for a multitude of other malformed or invalid requests, usually yielding HTTP response codes from the 4xx and 5xx range. A detailed documentation on those is available in the 
RFC2616~\footnote{W3C, \textit{10 Status Code Definitions}, \url{http://www.w3.org/Protocols/rfc2616/rfc2616-sec10.html} (Sep 2004)}. 
    This equally applies to other protocols.\\

    Given the above, one may wonder about the disadvantages of blocking, and indeed, it can have negative consequences. To give an example, an attacker can infect victim's cookies with an overlong string on domain A and thereby impact availability of domain B. Vela published an article on that attack technique in 2009, using Google Analytics as a mediator to cross the domain border and cause denial of service (DoS) attacks to almost arbitrary websites, employing the Google Analytics tracking code~\footnote{Vela, E., \textit{How to use Google Analytics to cause denial of service (DoS) to a client from some website}, \url{http://sirdarckcat.blogspot.com/2009/04/how-to-use-google-analytics-to-dos.html} (April 2009)}. Another point is blocking requesting and returning a custom crafted response, which can also introduce information leaks and illegitimately unveil information on the existence of database entries and items on remote file systems. Blocking requests and sending error messages can further be exploited 
when attacking web services and encrypted XML data, as pointed out by Jager et al.~\cite{jager2011break}. Same effects can be observed when illegally crafted requests are sent to web servers protected by web application firewall (WAF). The WAF often ships a specific error code once an attack has been detected. Gauci et al. created a \textit{WafW00f}/\textit{waffit} tool, a small library capable of fingerprinting a web application firewall by analyzing the responses sent by web application in case malicious data is part of the request headers and body~\footnote{Gauci, S. et al, \textit{waffit -- A set of security tools to help you audit your WAF }, \url{http://code.google.com/p/waffit/} (Jan 2012)}. In general, blocking might help narrowing down the attack surface, yet it might also introduce new attack vectors if it is applied in an improper manner. It is worth to mention that further edge cases where blocking requests and displaying custom error data and warnings causes new security threats to arise exist. 
Their fringe importance locates them outside the scope of this work.  

    \subsubsection{Stripping and Replacing}
    \label{subsubsec:4.3.2.stripping_and_replacing}
    % removing blacklisted characters / non white-listed characters

    To define what is not welcome is often considered to be the most obvious way to deal with unsolicited input. Consequently, removal of all matching occurrences in incoming user data is performed. Having been practiced for over a decade in web application security, this approach has been proven effective and robust, especially once classic mistakes were eradicated. One prominent example implemented in the server-side runtime PHP is \textit{strip\_tags()} function meant to protect against common HTML injections and XSS attacks. This particular function demonstrates in a simple yet convincing way how stripping as a protection mechanisms works, how it limits the capabilities of user generated content, and finally, how attempts to slightly extend the granularity to permit a broader range of seemingly harmless content being turned into a small security catastrophe. The \textit{strip\_tags} function was originally meant to completely strip anything from the argument-supplied text that remotely resembles HTML or 
similar structural data. This signified that anything from the first \textit{<} character (U+003C) to the last balanced \textit{>} character (U+003E) got removed.\\
    
    Perceiving this as too harsh and invasive to be useful, many users then requested more flexibility to be able to use harmless tags, such as the \textit{b} tag for bold text, \textit{i} for italics and similar optical and structural enhancements. The PHP development team added an optional second parameter called \textit{\$allowable\_tags}, which allows passing a string containing allowed HTML in a concatenated form. A developer aiming to permit usage of a and b tags would call \texttt{strip\_tags(\$content, '<a><b>')}. Unfortunately, \textit{strip\_tags} using \textit{\$allowable\_tags} does not consider attributes at all. The XSS protection is therefore completely annihilated if no further very complex string treatment happens. This feature should therefore be avoided unless attribute injection are either filtered by a different tool afterwards or XSS is not a threat for the rendered document -- an example vector was created to illustrate this behavior~\footnote{Heiderich, M., \textit{Example for strip\_
tags based XSS}, \url{http://codepad.org/FBgfCiPI} (Dec 2011)}. Our research showed that a surprising amount of circa 450 open source libraries and website frameworks still uses \textit{strip\_tags} with the second parameter. They are then at high risk of vulnerability against XSS, regardless of content filtering~\footnote{Google Inc., \textit{Google Codesearch}, \url{http://code.google.com/codesearch#search/&q=strip_tags\s*\\([^()]+,['\"]<} (Jan 2012)}.\\

    Still, web applications are using stripping and replacement for securing the incoming or outgoing data against possibly malicious substrings. In addition to stripping HTML data, several libraries and tools strip suspicious keywords, which often leads to confusing effects and rarely generates an increased level of security. During our reserach, we have discovered several websites stripping substrings such as \textit{fromCharCode} from the user-generated data before being sent to the user agent. Incorrect stripping caused those websites to remain vulnerable against an XSS attack using this function in a number of ways. One idea would be to use the string \textit{fromCfromCharCodeharCode} to have the library strip out the substring \textit{fromCharCode} and consequently have the remaining text result in being \textit{fromCharCode} again. Other attacks against blind stripping involve obfuscation techniques using simple methods such as injecting String['fromC'+/harC/.source+'ode'] to bypass this naive 
mitigation approach. A better but still unreliable way to deal with ``forbidden substring content'' is to actually replace the possible attack code with a harmless token, such as a sequence of whitespace characters. Nevertheless, even well-thought replacement techniques can be circumvented by a thrifty attacker. In our recent article, we have demonstrated a successful attack against content stripping and replacement mechanisms once existing in the Amazon website. There, an attack payload has to be carefully filled with nested comments to get around website's protection mechanism~\cite{somorovsky2011all}.

    \subsubsection{Escaping}
    \label{subsubsec:4.3.3.escaping}

    Working on a similar level as stripping and replacing, escaping ensures that certain possibly harmful or syntactically relevant characters are being prefixed with yet another character. This is to indicate to a parser that the syntactical meaning is neutralized and the actual character representation should be chosen for processing. Escaping is often used in connection with treatment of user-generated string data for later database management system's usage. Many run-times, such as PHP, provide native built-in methods for escaping data to be stored in MySQL or other databases. In essence, this means that several characters that could potentially break a string delimiter in a database SQL query need to be prefixed with a backslash character (U+005C). This prefixing instructs the parser to keep for instance delimiters intact and therefore prevent a possible injection scenario. A string such as \textit{O'Malley} would be represented as \textit{O\textbackslash'Malley}. A representation in SQL could 
accordingly be looking like this: \texttt{SELECT * FROM users where lastname = 'O\textbackslash'Malley'}.\\

    In 2006, Shiflett reported an interesting attack against escaping-based protection mechanisms for databases and MySQL. He employed the Asian GBK character set and a PHP parser confusion nested in the code for the method \textit{escape()}, making sure that one Chinese character at Unicode tale position U+BF5C will be converted into two single byte characters -- U+00BF and U+005C~\footnote{Shiflett, C., \textit{addslashes() Versus mysql\_real\_escape\_string()}, \url{http://shiflett.org/blog/2006/jan/addslashes-versus-mysql-real-escape-string} (Jan 2006)}. The U+005C character would actually ``escape the escape'' and result in the string sequence \textbackslash\textbackslash. Therefore, it would allow a properly escaped single-quote to be parsed in its syntactical representation, break a delimiter and be a cause for an SQL injection vulnerability. In scope of this thesis, escaping for databases and server-side applications is less important, thus we will rather focus on CSS escapes in Section~\ref{subsubsec:5.4.8.attacks_using_innerhtml} and Section~\ref{subsubsec:5.4.9.attacks_using_csstext}. CSS escapes have a similar purpose to escapes used in SQL; namely, they allow a developer to escape and ``defuse'' syntactically relevant characters in string properties. CSS escapes are described and specified by the W3C for CSS1 and CSS2~\footnote{W3C, \textit{Using character escapes in markup and CSS}, \url{http://www.w3.org/International/questions/qa-escapes} (Aug 2010)}. No changes regarding escaping have been proposed in CSS3 and later versions. \\

    Note that JavaScript Unicode escapes are available as well -- and contrary to JavaScript octal and hexa-decimal escapes can be used to evaluate code without any form of decoding. The following code snippet will execute in most Gecko-based user agents: \texttt{\textbackslash u0061lert(1)}. A bypass for the Dojo JavaScript Sandbox has been crafted by Heyes using this technique; this is being detailed on in Section~\ref{subsubsec:4.10.2.dojo_sandbox}.

    \subsubsection{Encoding}
    \label{subsubsec:4.3.4.encoding}

    Encoding incoming user-generated data into an entity representation is an effective way of mitigating scripting and markup injection attacks. It is particularly useful in case a developer wants to make sure an attribute value needs to be secured from breaking out with an injection of arbitrary data. Most server-side run-times provide native functions to do so. PHP, for instance, offers two functions labeled \textit{htmlentities()} and \textit{htmlspecialchars()}. Those usually do not encode any arbitrary character into an entity representation. Only a selected range of considerably dangerous characters will be encoded. Depending on the parameters, \textit{htmlspecialchars()} encodes the characters U+0022, U+0026, U+0027, U+003C and U+003E, \textit{htmlentities()} encodes all characters having HTML entity references). We call this ``selective encoding``. Despite the simplicity of these functions, attackers managed to discover bypasses relying on character set-based obfuscation. Shiflett reported a UTF7-
based XSS vulnerability which enabled payload to work despite proper \textit{htmlentities} encoding~\footnote{Shiflett, C., \textit{Google XSS Example}, \url{http://shiflett.org/blog/2005/dec/google-xss-example} (Dec 2005)}. The problem here is that character sequences used in UTF7 are not among those characters in the range encoded properly by these functions. This includes U+002B and U+002D. The UTF7 representation for the string \textit{<script>alert(1)</script>}, as depicted here, would thus not be affected by the selective encoding of \textit{htmlentities} or \textit{htmlspecialchars}, provided that no further precautions are taken: \texttt{+ADw-script+AD4-alert(1)+ADw-/script+AD4-}.\\


    Further problems with this kind of selective encoding may occur for websites explicitly created for Internet Explorer. Alongside the single-quote and double-quote (U+0027, U+0022), this browser accepts another attribute delimiter token -- the back-tick (U+0060). This character is not considered critical by the \textit{htmlentities} and \textit{htmlspecialchars} functions, so it will pass without additional entity encoding. What is more, characters suitable for introducing CSS cross-origin content-stealing attacks, as described by Huang et al., are not encoded either~\cite{huang_protecting_2010}. Whether selective encoding is successful to secure a web application or document loaded in a browser, strongly depends on the context the encoded data is being rendered in. In case an attacker attempts to utilize an attribute injection into an event handler, selective encoding might not be suitable at all, since browsers do not differentiate between canonical versus encoded text inside HTML element attributes. 
Similar problems occur for XML islands inside HTML documents, or simply XML documents. For those XML documents, several tags and elements are allowed to contain encoded text. Section~\ref{subsubsec:5.4.8.attacks_using_innerhtml} will elaborate further on comparable attacks involving inline SVG data embedded in a HTML document. Double-encoding will sometimes help preventing attacks, but in many situations, for instance with multiple innerHTML property access, even countless rounds of encoding cannot prevent an attack. In this case, several characters will have to be stripped selectively, as mentioned in Section~\ref{subsubsec:4.3.2.stripping_and_replacing}. On the other hand, encoding any single character, including word characters and Unicode data, might create a vast overhead regarding bandwidth and time for processing. While -- depending on the aforementioned context -- indiscriminate encoding may be more secure than selective encoding, the performance and bandwidth implications might keep the developers 
and site owners from relying on it. \\

    \subsubsection{Rewriting Code}
    \label{subsubsec:4.3.5.rewriting_code}

    One of the most common protection methodologies applied for modern and complex web applications is the rewriting of incoming user data. More importantly, it lays in detecting and subsequent rewriting and sanitizing of the code by a given rule-set or document definition / Interface Definition Language (IDL). The aforementioned methods of blocking, stripping, replacing or encoding are often insufficient in their efforts to allow users to visually and semantically enhance the posted content. To illustrate, let us take an author of a blog post content in a WordPress blog software environment who may wish to add images and text formatting to the posted data before review, yet the article content should not be able to contain any active markup that might lead the reviewing moderator to leaking sensitive data or login credentials. In essence, an application may want to permit harmless markup and HTML posting to the users, while at the same time it strives to avoid having the submitted and afterwards displayed 
content contain active markup, script or plug-in content. Clearly paradoxical in a way, this challenge is rather hard to find a good solution to. We will elaborate on details of this case in Section~\ref{subsubsec:5.4.6.bypassing_server_side_xss_protection}. Nevertheless, tools and libraries have faced the challenge of telling apart active and inactive markup, resulting in a wide array and availability of software designed to filter markup and rewrite client-side code. For plain XSS protection and markup sanitation, the HTMLPurifier composed by Yang is available for PHP developers. AntiSamy, a similar software written and maintained by Li and Dabirsiaghi, can be used for Java applications, while the Microsoft Windows-based server and application landscape enjoys a software called SafeHTML.\\

    Most of the tools we have just mentioned apply complex operations to the incoming data. Thus, they often do not return any of the incoming data but rather deliver a whole new string resembling the original input rather than consisting of it%?. 
    The HTMLPurifier, for instance, tokenizes the incoming data and tries to build a DOM tree with matching nodes, attributes and values. After that, the invalid tokens are removed, while the remaining data is matched against a XHTML doctype definition (DTD) and  non-matching data is removed. The remaining data is then analyzed node by node and finally a string consisting of the serialized DOM tree data is crafted and returned. This way it is harder for an attacker to conduct strikes employing unbalanced attributes, omitting closing tags, mixing attribute delimiters, escaping tricks and alike techniques capable of confusing a regular expression-based filter/parser. We will cover existing bypasses unveiled during our research against HTMLPurifier and other filter tools, regardless of their DOM-based token-supported approach, as Section~\ref{subsubsubsec:5.4.6.2.bypassing_htmlpurifier} and those following will demonstrate. While purely regular expression-based HTML filters do exists as well, we will not 
include them in our work, as we believe that protection they deliver is weak by design. %Our tests showed software such as HTMLawed~\footnote{Patnaik, S., \textit{htmLawed -- PHP code to purify \& filter HTML}, \url{http://www.bioinformatics.org/phplabware/internal_utilities/htmLawed/} (Oct 2011)} isnah :) fundamentally broken -- using this kind of tools is not recommended for applications hosting sensitive data. \\

     Projects such as Google Caja and JSReg (mentioned later on in Section~\ref{subsubsec:4.10.1.jsreg}) operate under different set of goals. Google Caja receives JavaScript code in string form and uses its internal engine to rewrite it in its entirety. The process of code conversion is called \textit{cajoling}. Caja only allows a subset of JavaScript features, similar to other projects like \textsc{Gatekeeper}~\cite{Guarnieri:2009:GMS}. A drawback of such approach is that complex libraries might need to be rewritten in order to work correctly. Only if the Caja runtime (called \textit{Cajita}) has been included via \textit{<script>} element, a cajoled script will function. Additional disadvantages of Caja include its complexity and a certain code overhead generation. Cajoling a simple \texttt{alert(1)} results in circa 150 lines of code. Cajoling the HTML sequence \texttt{<a href="javascript:alert(1)">click</a>} results in circa 130 lines of code, and includes a rewritten \verb|<a>| tag no longer containing 
\textit{href} attribute, just an ID for later event binding in the Caja-generated script. The Caja approach does not only rewrite JavaScript, as it affects HTML and CSS as well -- the developer team is aware of the fact that both languages contain many possibilities to execute JavaScript code. Our tests indicate that Caja is not capable of working well with valid but heavily obfuscated code such as non-alphanumeric JavaScript~\footnote{Heyes, G., \textit{Decoding non-alphanumeric code with Hackvertor}, \url{http://www.thespanner.co.uk/2011/08/03/decoding-non-alphanumeric-code-with-hackvertor/} (Aug 2011)}. Furthermore, Caja is not meant for lightweight and real-time code analysis, but rather one time conversion and later usage of the cajoled code. Due to the overhead introduced in the cajoling phase, the resulting code will take more time to execute. The same happens as soon as browser-specific artifacts are being used in the code, for example when E4X fragments are embedded in the obfuscated code. \\

    Another feature of Caja is insuring a correct behavior of the cajoled code, meaning that it does not cause disturbance to user experience. Certain policies exist for taming the alert and comparable modal information and dialog methods, so that they cannot be called more than ten times in a row. To be able to deal with malicious or obtrusive Flash files, Caja is can enforce similar policies. Flash files can be tamed by restricting script access and using an up-to-date player to avoid security problems present in Flash player version 8 and below. A JSON parser implementation guarantees that user agents without JSON DOM API's support will be able to deal with malicious JSON securely. It also grants a prohibiting evaluation via JSON labels and values. Access to several native objects is restricted, for instance the \textit{window} object access attempt will just return a standard object representation -- and not the DOM window as to be expected by the attacker.

  \subsection{Client-Side Filtering}
  \label{subsec:4.4.client_side_filtering}
    
    A major problem persists in server-side XSS filters because they cannot see data and parameters that are only exchanged between different client-side layers. Those filters need to enlist for obtaining external help for exchanges pertaining to location hash value, Flash parameters passed via \textit{location.hash} discussed in Section~\ref{subsubsubsec:2.4.3.1.flash_plugin_security}, parameters for Adobe PDF files and similar data. Websites often expose vulnerabilities that are based on programming mistakes occurring in the JavaScript and especially Flash code. A whole  class of vulnerabilities has been attributed to this particular visibility problem and it will be discussed in Section~\ref{subsubsec:5.4.4.domxss}. To be able to mitigate attacks using DOMXSS, Flash bugs and similar vulnerabilities, browser vendors and extension authors started to follow a different pattern for user protection -- client-side XSS and attack filters. Pioneering in those regard is Microsoft Internet Explorer 8, which employs 
an integrated XSS filter, as well as Firefox's extension NoScript, which implements a similar feature. Webkit-based user agents, such as Google Chrome, have likewise started to add XSS filter support - here labeled XSS Auditor. Next paragraphs will elaborate on those client-side filter solutions but not go in depth of breaking them. The content in Section~\ref{subsubsec:5.4.7.bypassing_client_side_xss_protection} will provide more details on how to break any given bypass for client-side filtering solutions, when one aims at injecting JavaScript and other active code.

    %\subsubsection{Overview on Client Side Filtering}
    %\label{subsubsec:4.4.1.overview_on_client_side_filtering}

    \subsubsection{Microsoft Internet Explorer XSS Filter}
    \label{subsubsec:4.4.2.internet_explorer_xss_filter}

    Microsoft Internet Explorer 8 introduced a novel feature called ``MSIE XSS Filter''. This addition was designed by Ross and targeted  detection of malicious substrings in the URL, whilst consequently deactivating their matching occurrences in the document markup to prevent scripting, injection and XSS attacks. The MSIE XSS filter was one of the first active mitigation tools residing in the user agent itself. Unsurprisingly, it has inspired other vendors and developers to release similar instrumentations for other user agents, namely the NoScript XSS filter for Firefox mentioned in Section~\ref{subsubsec:4.4.4.noscript_xss_filter} and the Webkit XSS Auditor discussed in Section~\ref{subsubsec:4.4.3.chrome_xss_auditor}, have followed suite.\\

    The MSIE XSS Filter resides between the network stack and the markup parser, checking for matches between URL fragments and the resulting markup in the response body. If those matches are present, and furthermore match against a set of regular expressions employed to tell apart malicious from benign data exists, the MSIE XSS Filter will modify the occurrences in the markup and replace certain characters to invalidate and deactivate the potentially malicious injected code. To avoid raising too many false alerts, the detection performance is limited to vectors potentially executing JavaScript or similar active code. This includes forms, active VML code, CSS import directives, \textit{link}, \textit{object} and \textit{meta} elements. URI/response body matched indicating data exfiltration attacks by dangling tags and half-open attributes are not filtered, as described by Heyes~\footnote{Heyes, G., \textit{HTML script-less attacks}, \url{http://www.thespanner.co.uk/2011/12/21/html-scriptless-attacks/} (Dec 
2011)} and Zalewski~\footnote{Zalewski, M., \textit{Postcards from the post-XSS world}, \url{http://lcamtuf.coredump.cx/postxss/} (Dec 2011)} in 2011. Since the filter is designed for Internet Explorer and has filter rules that are not generically composed, proprietary XSS vectors against Google Chrome, Mozilla Firefox and the Opera browser are not being detected. This differs from functioning of SafeHTML mentioned in Section~\ref{subsubsubsec:5.4.6.3.bypassing_safehtml}, as well as its client-side representation \textit{toStaticHTML()}. In 2009, Kouzemtchenko published detailed research on how to bypass the MSIE XSS Filter. He mainly focused on fragmented attacks, JavaScript execution lacking parenthesis and similar vectors~\footnote{Kouzemtchenko, A., \textit{Examining And Bypassing The IE8 XSS Filter}, \url{http://www.slideshare.net/kuza55/examining-the-ie8-xss-filter} (Jul 2009)}.\\

    As signalized in Section~\ref{subsubsec:4.3.2.stripping_and_replacing}, replacing characters in what is suspected to be be a malicious string can be more dangerous than expected. In 2009, Vela et al. discovered an attack against the MSIE XSS Filter. They have abused the fact that in an injection scenario certain characters are being replaced. The replacement allowed them to have a decoy HTML attribute be disabled -- and thereby having the one containing the actual payload be activated. This simplified example should illustrate the bug: \texttt{<img alt="x onerror=alert(1) x" src="x.png">} would become \texttt{<img alt\#"x onerror=alert(1) x" src="x.png">} and thereby activate the \textit{onerror} by eliminating the quote delimiting the \textit{onload} attribute value. This technique required two injection points on a website but was common enough to affect Twitter, Facebook, Google, Wikipedia and many other popular websites. A security update was provided by Microsoft quickly afterwards. Since then the 
MSIE XSS Filter has recovered from its severely damaged reputation, as it has become increasingly harder to find working bypasses. Future-wise, it is suspected that the addition of elements and attributes in HTML5 might cause some novel gaps between detection rules and actual browser capabilities. A detailed discussion on the general topic of bypassing client-side XSS protection will be furnished in Section~\ref{subsubsec:5.4.7.bypassing_client_side_xss_protection}. The code in Listing~\ref{lst:ie-xss-filter} illustrates one of the (meanwhile updated) rules the MSIE XSS Filter is utilizing to detect malicious content. The syntax format is related to the Perl Compatible Regular Expression (PCRE) notation. The only notable deviation is the \textit{\{character\}} notation, marking the character to be replaced by a hash (U+0023) to neuter the suspected attack string.  

\begin{lstlisting}[captionpos=b,caption=MSIE XSS Filter rule example code; Extracted in 2009 by analyzing the containing DLL file,label=lst:ie-xss-filter]
/* detecting @import in style elements */
{<st{y}le.*?>.*?((@[i\\])|(([:=]|(&[#()\[\].]x?0*((58)|(3A)|(61)
  |(3D));?)).*?([(\\]|(&[#()\[\].]x?0*((40)|(28)|(92)|(5C));?))))} 
\end{lstlisting}

    \subsubsection{Webkit/Google Chrome XSS Auditor}
    \label{subsubsec:4.4.3.chrome_xss_auditor}

    The Webkit XSS Auditor is an experimental XSS filter implementation established on design canvas presented by Bates et al. in 2010~\cite{bates2010regular} (Note here that a prototypic implementation was available prior to the release of the paper). This publication outlines authors' research on design-based weaknesses of the Internet Explorer XSS filter and mainly criticizes the fact that an XSS filter installation resides between network stack and HTML parser, which might cause it to suffer from visibility impairments leveraging bypasses and vulnerabilities. Three attack classes in total, all targeted against this particular XSS filter, are discussed in Bates' paper. Firstly, we have the data exfiltration attacks utilizing existing scripts, mostly based on architectural and application specific flaws. Secondly, the induced false positives aimed at stopping benign scripts from executing or manipulating existing code segments due to selective escaping of the XSS filter. Thirdly, there is the so called pre-
parsing mediation, the effect of application-specific transformations on the rendered markup and script code. Several sample attacks are introduced and discussed by the paper as well.\\

    Consequently, Bates and colleagues have introduced a different design for the Webkit XSS Auditor prototype and proposed to situate the XSS filter between HTML parser and JavaScript engine for better detection results and reduced attack surface. Bearing similarities to the Internet Explorer XSS filter, the Webkit XSS Auditor needs to compare incoming data with the rendered source to avoid false positive alerts. However, the NoScript XSS filter described in Section~\ref{subsubsec:4.4.4.noscript_xss_filter} acts differently and accepts a higher amount of false alerts as a trade-off for better attack detection. During our reserach, we tested the Webkit XSS Auditor extensively and discovered several bypasses. An in-depth discussion of bypassing the Webkit XSS Auditor, including the considerations on the weaknesses of this approach alongside the implementation flaws, is available in Section~\ref{5.4.7.2.bypassing_chrome_xss_auditor}. The current version of the Webkit XSS Auditor is continuously being optimized 
and hardened against new bypasses. Ross, the creator of the Internet Explorer XSS filter, published a rebuttal after the Bates paper was released. He addressed further issues resulting from the very late XSS filtering introduced by the Webkit XSS Auditor, underlining some of the concerns that came to light from our research results~\footnote{Ross, D., \textit{XSS Filter Tech: Later is Better?}, \url{http://blogs.msdn.com/b/dross/archive/2011/12/20/xss-filter-tech-later-is-better.aspx} (Dec 2011)}.

    \subsubsection{NoScript XSS Filter}
    \label{subsubsec:4.4.4.noscript_xss_filter}

    NoScript is a Firefox extension designed to provide several layers of protection against a variety of attack techniques. Its author, Giorgio Maone, has initially created it to protect himself from a Firefox code execution bug. He chose the way of selective permissions. Essentially, NoScript's initial task was to help maintain and enforce a white-list of trusted domains that are unlikely to execute malicious JavaScript. At the same time any other domain absent from this list would not be able to execute scripts. Current versions of NoScript contain significantly more security features than the original releases. The Application Boundaries Enforcer (ABE) is one example, devoted to warding off attacks across networks such as Intranet XSS. Other functions comprise ClearClick protecting against Clickjacking attacks by detecting and blocking transparent and overlapping frames and similar elements, optional enforcement of Strict Transport Security (STS) and ultimately a strong and  reliable reflected XSS filter.
\\ 

    Unlike Internet Explorer XSS filter and Chrome XSS Auditor, the NoScript XSS filter does not confirm the existence of potentially malicious code padded in via URL parameters but checks against the parameters only. By default, the XSS filter verifies request parameters if an untrusted site is left and a trusted site is being requested. In case this usage pattern occurs and the request parameters contain suspicious characters and substrings, the request URI will be changed before the markup is being rendered. All suspicious parts of the URI will be switched to an upper-case representation, while special characters such as parenthesis, lesser than and greater than will be replaced by whitespace. Additionally, a unique ID is attached as location hash. The request URI fragment \texttt{insecure.php?a="><img/src= onerror=alert(1)} will be changed to \texttt{insecure.php?a= > img\%2Fsrc= ONERROR=ALERT 1 \#some\_random\_number}. \\

    Our research has shadowed the NoScript XSS filter for several months and yielded many bypasses, all discussed in Section~\ref{5.4.7.1.bypassing_noscript}. We targeted the NoScript XSS filter specifically but our secondary focus was on the scarcely published field of script-less attacks, vectors targeting environments where script execution and active content are limited in the degree of their capabilities or simply disabled.

    \subsubsection{Risks and Limitations}
    \label{subsubsec:4.4.5.risks_and_limitations}

    While the general approach of blocking untrusted domains from deploying active content as detecting suspicious patterns in the URL and modifying affected parameters to disable possible attacks might sound feasible, the challenges of those are obvious as well. The major problem behind selective domain trust is posed by its simplicity and the requirement of having a possible victim (who usually is a regular non-technical Internet user) decide whether to block or agree to the script execution. Will a user be qualified to decide if a particular domain can potentially spread malware or just benign script content? Modern websites often require a large quantity of JavaScript code to function properly. For performance reasons, these scripts are often deployed from servers and networks optimized for delivering static content -- so called Content Delivery Networks (CDN). Those CDN are usually using a different domain and therefore have to be authorized by NoScript as well. Furthermore, advertisers deploy their 
content from yet another set of domains and similar strategies are employed by providers of logging and tracking scripts such as Google Analytics. A popular technical web-log ``Techcrunch'' will require a user to authorize an overall of fourteen script-deploying domains to display all available content. Some of those domains will then attempt to load more content from additional different domains. A user is thus often tempted to loosen restrictions and temporarily \textit{enable} all script and use the website easily. Otherwise, he can allow scripts in general, which leaves at least one major purpose of NoScript useless. \\

    Large body of research regarding Domain Name System (DNS) security should be pointed out. Once domain name system has been attacked, and a domain name cannot be trusted to be resolving the desired IP address anymore, the domain white-list feature of NoScript is endangered in terms of providing security, too. Man-in-the-Middle (MITM) attacks are also capable of bypassing the protective coat of NoScript's domain white-list. Once one of the white-listed domains such as \textit{google.com} is used to deploy malicious code, the protection is bypassed. Especially platforms like Google Code ease the deployment of malicious code helping with the cause a working NoScript bypass.\\

    The ``bypassability'' based on mismatches between examined incoming data and resulting rendered and executed code clearly indicates problems with reflected XSS filters deployed by Webkit browsers and the Internet Explorer, as well as NoScript. A thrifty attacker can go as far as to abuse the attempted neutering of the XSS filters for malicious purposes and have the filter assist him in transforming harmless code into a valid attack vector. As it will be showcased in Section~\ref{5.4.7.2.bypassing_chrome_xss_auditor}, our research unveiled a minor bug in the Webkit XSS filter causing an injection to work only after the filter modified the rendered data. Similarly, Vela et al. published on a universal XSS attack caused by the Internet Explorer 8 XSS filter in 2009, when it has literally rendered well-protected websites vulnerable against XSS because of a bug in the IE8 XSS filter~\footnote{http://p42.us/ie8xss/Abusing\_IE8s\_XSS\_Filters.pdf}.\\

    There are still prevalent problems that one can observe with solutions like the described XSS filters. On one hand, it is the limitation of capability to effectively work only against known bad; the filter can detect solely what is known to be potentially dangerous and able to execute scripts or worse. Thereby, attackers have the possibility to enumerate the substrings being detected and find variations suited to bypass the filter. Our research unveiled a plethora of these bypasses, which we go over in depth in Section~\ref{subsubsec:5.4.7.bypassing_client_side_xss_protection}. On the other hand, the discrepancies between the inspected data sources -- address bar, request data and others -- versus the actually rendered output might support feasibility of bypasses. So far only NoScript relies exclusively on the data used in the address bar but does not compare it to the rendered output. This generates benefits in detection performance and theoretically reduces the amount of possible bypasses, but yields 
more false alerts that have to be fixed within the NoScript extension itself. Several versions of the Webkit XSS filter were prone to attacks via mismatches between incoming data and rendered output and these bugs will be discussed in Section~\ref{5.4.7.2.bypassing_chrome_xss_auditor}. At present, none of the available XSS filters is capable of analyzing script behavior for suspicious patterns -- nor can it provide a capability-based approach to hinder or block access to crucial DOM properties while allowing regularly behaving scripts to pass. We have put forward this type of development in 2011~\cite{heiderich2011iceshield}.

  \subsection{Content Security Policy}
  \label{subsec:4.5.content_security_policy}

  The Content Security Policy (CSP) can be viewed as an experimental security extension currently available in modern Gecko-based user agents and -- in slight deviation in Google Chrome browsers. In 2010 Stamm et al. published on CSP, presenting on its origins and the rationale behind it. Another publication details the prototypic Firefox version supporting CSP created by Sterne~\cite{stamm2010reining}. On his website, Sterne regularly publishes details of the currently available CSP version - ranging from 0.1, 0.2, 1.0 and  2.0 at the time of our write-up ~\footnote{http://people.mozilla.com/~bsterne/content-security-policy/details.html}. Sterne states to have been inspired to create CSP by the security researchers RSnake~\footnote{http://ha.ckers.org/blog/20070811/content-restrictions-a-call-for-input/} and Gerv~\footnote{http://www.gerv.net/security/content-restrictions/}. \\

  The primary purpose of CSP is a non-complex, competent and flexible policy enforcement for dynamic website content such as links, scripts, external images, frame sources, redirects and plug-in content. Targeting mitigation of XSS attacks and CSRF vulnerabilities, CSP limits  websites' capability of using external resources, inline scripts, event handlers and certain JavaScript language constructs like \textit{eval}, the function constructor and \textit{setTimeout}, \textit{setInterval} and consequently \textit{setImmediate}, for as long as their argument is a string and not a function. By default, CSP will also not allow \textit{javascript:} URIs, and neither will \textit{data:} URIs be permitted for images, nor CSS data for \textit{link} tags or Iframes, \textit{script} tags and comparably dangerous elements. \\

  The CSP policy directives are delivered via HTTP headers and aim towards providing a handle to control any possible type of external resource the browser is capable of rendering. Additionally, a domain white-list might be used to exclude certain trusted domains from having their content blocked by the user agent. Another major feature of CSP is an option to define a report URI -- an external resource to where the reported CSP rule violation can be sent for later analysis. During the OWASP Summit 2011, Heyes and Heiderich raised the question of having these reports be a new vector to attack back-end architectures of web applications using CSP~\footnote{OWASP, \textit{Category:Summit 2011 Tracks}, \url{https://www.owasp.org/index.php/Category:Summit_2011_Tracks} (Jan 2012)}. 
  The question has not yet been answered comprehensively and no final decision on user agent driven encoding of the report data as a way to mitigate attacks on the reporting backend has been reached.\\

  The Chromium team has announced that Chromium 13 will contain CSP support by June 2011. We have not researched the level of implementation or possible bugs up till now. Since Chrome does not support E4X, several of the vulnerabilities mentioned in Section~\ref{subsubsec:5.4.12.bypassing_csp} are unlikely to succeed. Despite the early stage of the Google Chrome CSP implementation at the time of writing, the second CSP bypass mentioned in Section~\ref{subsubsec:5.4.12.bypassing_csp}, which is using a self-including script, has been proven to work fine on Firefox 9.0a1. Conversely, it is blocked successfully on Chromium 15.0.871.0, which accompanies it with the console output indicating activity of the CSP enforcement: "Refused to load script from 'http://example.com/xsp.php' because of Content-Security-Policy.``\\

  The CSP specification draft is currently still undergoing changes. These include label alterations for the CSP directives, impact on the user agent behavior, and comprehensiveness of the possible external resources to permit and prohibit other rather exotic inclusions for web docs -- including XSL Transformation data (XSLT), embedded SVG/WOFF fonts and other rather exotic includes for web documents.

  %\subsection{HTML5 and ES5 Strict Mode}
  %\label{subsec:4.6.html5_based_website_security}

    %\subsubsection{Cross Origin Resource Sharing}
    %\label{subsubsec:4.6.1.cross_origin_resource_sharing}

    \subsection{Iframe Sand-Boxing}
    \label{subsubsec:4.6.2.iframe_sandboxing}


    Sand-boxed Iframes haven been specified by the W3C and WHATWG for HTML5 back in 2008~\footnote{HTML5 Tracker, \textit{Diff From: 1642 To: 1643}, \url{http://html5.org/tools/web-apps-tracker?from=1642&to=1643} (May 2008)}. The aim was to bring more security and better capability control for framed and potentially attacker-controlled website content. In essence, sand-boxed Iframes allow a developer to limit the scripting capabilities for the content they load -- may it originate from a same domain URL, cross-domain content or a non HTTP URI. The HTML5 sand-boxed Iframe feature has been inspired by the proprietary attribute \textit{security} for Iframes on Internet Explorer~\footnote{MSDN, \textit{SECURITY Attribute}, \url{http://msdn.microsoft.com/en-us/library/ms534622(v=vs.85).aspx} (Jan 2012)}. This attribute applied to an Iframe and set to value \textit{restricted} will force the browser to render the document encapsulated by the Iframe in the \textit{Restricted Sites Zone}. This process have been 
mentioned in Section~\ref{subsubsubsec:2.4.1.2.internet_explorer_zone_model}.\\

    Sand-boxed Iframes allow more granular capability control than their aforementioned predecessor. The goal of the specification was to give developers a tool to not only switch JavaScript support on and off, but to also to allow limited scripting and restricted top frame access. The sandbox specification currently provides four combinable parameters for the sandbox attribute value. In case an empty sandbox attribute is given, all possible restrictions apply. That means that Iframe content cannot execute any scripts, plug-in content, has no top or parent access, cannot submit any forms nor can it perform any other actions other than displaying static HTML. We will now furnish the list of the aforementioned parameters:

    \begin{itemize}
      %
      \item \textbf{allow-forms} Setting this attribute will enable the Iframe content to submit forms. Note that using the \textit{target} attribute, \textit{formtarget} and other tricks to direct the returned response to a different frame will not work here, although early implementations of some user agents were able to be tricked into breaking the sandbox in this manner. Furthermore, one has to be aware that JavaScript URIs are not available for forms unless the \textit{allow-scripts} keyword is present in the sandbox attribute~\footnote{WHATWG, \textit{The allow-forms keyword}, \url{http://www.whatwg.org/specs/web-apps/current-work/multipage/the-iframe-element.html#attr-iframe-sandbox-allow-forms} (Jan 2012)}.
      %
      \item \textbf{allow-scripts} If this attribute value is given, the sand-boxed Iframe will be allowed to execute scripts. No matter if it is matching the hosting document's domain or not, the Iframe document origin will be set to a unique domain and therefore trusted as cross-domain content. No direct interaction between the Iframe and the hosting document is possible, except for using the \textit{postMessage} API~\footnote{WHATWG, \textit{The allow-scripts keyword}, \url{http://www.whatwg.org/specs/web-apps/current-work/multipage/the-iframe-element.html#attr-iframe-sandbox-allow-scripts} (Jan 2012)}.
      %
      \item \textbf{allow-same-origin} This attribute flag will set the Iframe origin to its actual domain instead of the aforementioned virtual origin. This means that if the hosting document and the Iframe share the same origin, no SOP restrictions apply for their communication. Combining \textit{allow-scripts} and \textit{alow-same-origin} weakens the sand-boxed Iframe concept severely, since the Iframe can theoretically use the hosting document's DOM API to remove the sandbox attribute from itself. Thereby bypassing possible \textit{allow-top-navigation} restrictions may occur~\footnote{WHATWG, \textit{The allow-same-origin keyword}, \url{http://www.whatwg.org/specs/web-apps/current-work/multipage/the-iframe-element.html#attr-iframe-sandbox-allow-same-origin} (Jan 2012)}.
      %
      \item \textbf{allow-top-navigation} Allowing top navigation enables sand-boxed Iframe to replace its hosting document with different content. This setting can be compared to allowing frame-busters. An attacker can replace the top document by using a form or link pointing to \textit{\_top} via the \textit{target} attribute, regardless of no JavaScript being enabled for the Iframe. Note that the HTML5 \textit{formtarget} attribute for the button element essentially accomplishes the same goal. Other browsing contexts are still protected from manipulation. Furthermore, plug-ins and other active code will not be allowed unless defined differently~\footnote{WHATWG, \textit{The allow-top-navigation keyword}, \url{http://www.whatwg.org/specs/web-apps/current-work/multipage/the-iframe-element.html#attr-iframe-sandbox-allow-top-navigation} (Jan 2012)}.
    \end{itemize}


    Internet Explorer 10 supports an additional yet proprietary attribute value labeled \textit{-ms-allow-popups}. With this flag, a developer can explicitly allow usage of the \textit{open}, \textit{alert}, \textit{confirm} and \textit{prompt} method. As a side note - beware of other methods to open new windows being affected as well, the \textit{showHelp} included. The aforementioned actions can be used by an attacker to obtain sensitive information or cause a denial of service by deploying modal dialogs in a loop. One more different proprietary feature available in Internet Explorer constitutes the most important reason behind this specific flag. We refer here to the \textit{createPopup()} method, originally created to display inline balloon help in websites running in a quasi-sand-boxed and limited privilege execution content~\footnote{MSDN, \textit{createPopup Method}, \url{http://msdn.microsoft.com/en-us/library/ms536392(v=vs.85).aspx}, (Dec 2011)}. The method is capable of rendering content 
originating from a frame outside the frame's borders by simply using absolute positioning. This way an attacker can inject scripted content from within an Iframe. That can for instance lead to overlapping a form and subsequent sniffing of user credentials or grabbing keystrokes. Only explicitly setting the \textit{sandbox} attribute to \textit{-ms-allow-popups} will enable using \textit{createPopup} from within a sand-boxed Iframe.\\

    Sand-boxed Iframes represent strong tool for developers to restrict possibly malicious content. The concept is well thought and first implementations have been tested during our reserach. Nevertheless, only two user agents party support the sand-boxed Iframe API at present. These are Internet Explorer 10 and Webkit / Google Chrome. Neither Firefox nor Opera provides support for this API. The latter suggests that this feature has not received satisfactory attention in the development community as of yet, as only few real-life implementations make actual use of sand-boxed Iframes thus far. It has to be over and above noted that the proposed MIME type supporting graceful degradation is virtually not in use to date. Most of the implementations we have tested were delivered through standard MIME types such as \textit{text/html} and not \textit{text/html-sandboxed}~\footnote{Shodan, \textit{Search Results for text/html-sandboxed}, \url{http://www.shodanhq.com/search?q=text/html-sandboxed} (Jan 2012)}.

    %\subsubsection{ES5 Strict Mode}
    %\label{subsubsec:4.6.3.es5_strict_mode}
    % Make sure to say it is NOT a security feature - but can be used as such

%  \subsection{Restricting Suspicious Websites}
 % \label{subsec:4.7.restricting_suspicious_websites}

%    \subsubsection{Internet Explorer Malvertising Detection}
%    \label{subsubsec:4.7.1.internet_explorer_malvertising_detection}

 %   \subsubsection{Firefox Domain Blacklisting}
 %   \label{subsubsec:4.7.2.firefox_domain _backlisting}

 %   \subsubsection{Google Chrome Website Blocking}
 %   \label{subsubsec:4.7.3.google_chrome_website_blocking}

 %   \subsubsection{Other Blacklisting Approaches}
 %   \label{subsubsec:4.7.4.other_blacklisting_approaches}

 %   \subsubsection{SSL Error Handling}
 %   \label{subsubsec:4.7.5.ssl_error_handling}
    % Mention FF SSL error handling, mixed content handling and iconography

  %\subsection{Protective Browser Extensions}
  %\label{subsec:4.8.protective_browser_extensions}

    %\subsubsection{NoScript for Firefox}
    %\label{subsubsection:4.8.1.noscript_for_firefox}

    %\subsubsection{noXSS for Firefox}
    %\label{subsubsec:4.8.2.noXSS}

    %\subsubsection{LocalRodeo for Firefox}
    %\label{subsubsec:4.8.3.local_rodeo_for_firefox}

    %\subsubsection{NotScripts for Chrome}
    %\label{subsubsec:4.8.4.notscripts_for_chrome}

    %\subsubsection{Securing Privacy and Cookies}
    %\label{subsubsec:4.8.5.securing_privacy_and_cookies}
    % Research other protective browser extensions and plugins
    % Check AMO, GCE and other extension stores

    %\subsubsection{Risks and Limitations}
    %\label{subsubsec:4.8.6.risks_and_limitations}
  
  %\subsection{Other Protection Mechanisms}
  %\label{subsec:4.9.other_protection_mechanisms}

  \subsection{JavaScript Sandboxes}
  \label{subsec:4.10.javascript_sandboxing}

    There are several JavaScript sand-boxing approaches, all aiming towards creation of a safe execution environment. Their potential is to allow users to submit active markup and JavaScript code that can later be rendered and executed without harming the security and privacy of others. The approach of generating a trusted DOM and thereby thriving towards elimination of XSS attacks might sound like yet another sand-boxing attempt, but it must be clearly stated that it is not. Various reasons and rationale of this fact will be deliberate on to a great extent in Chapter~\ref{sec:6.rethinking_client_side_web_security}. For now, the following paragraphs will introduce four JavaScript sand-boxing approaches, briefly discuss their features, drawbacks and usability for real life projects' applications. To learn more about alternate subsisting approaches for sand-boxing JavaScript, which have not been detailed here, Maffeis and colleagues' work in~\cite{MMT-CSF-TR09} and their subsequent publications can be 
consulted.

    \subsubsection{JSReg}
    \label{subsubsec:4.10.1.jsreg}

    JSReg is a JavaScript sandbox written entirely in JavaScript and heavily using regular expressions. The whole ``tokenization'' process is initiated by several regular expressions, targeted at detecting and extracting syntactically relevant code fragments, and then, wrapping and rewriting them into managed function calls. Created by Hayes, JSReg works as a JavaScript pre-parser deployed as a single JavaScript file. JSReg analyzes and tokenizes JavaScript code snippets, splits them into atomic units and rewrites the code so that properties and method calls are being wrapped to get control over the actually executed code. Having received great and well-deserved community recognition, JSReg remains an open source project maintained solely by its author. Several public challenges were announced to motivate users and researcher to break JSReg and find new security bugs and bypasses~\footnote{Heyes, G., \textit{JSReg sandbox challenge}, \url{http://sla.ckers.org/forum/read.php?2,29090} (June 2009)}.\\
    
    Due to its working logic and status JSReg has been broken a lot in the past. The aforementioned forum thread dedicated to reporting and discussing bypasses has reached several hundreds of posts. The majority among the submitted bypasses focused on exposing the global window object regardless of having the code rewritten by JSReg. This signalizes that the library attempts to hide certain critical properties from the submitted JavaScript code and deliver shadowed standard objects instead. JSReg can be considered a very interesting project, might nevertheless be not sufficiently secure to serve as DOM sandbox in a real life scenario just yet. Still, the JSReg library could easily be integrated into a trusted DOM environment and extend its feature-set.

    \subsubsection{Dojo Sandbox}
    \label{subsubsec:4.10.2.dojo_sandbox}


    The Dojo JavaScript framework is supplied with a sand-boxing environment created by Zyp~\footnote{Zyp, K., \textit{dojox.secure.sandbox}, \url{http://dojotoolkit.org/reference-guide/dojox/secure/sandbox.html} (Dec 2012)}. By description, it is supposed to give developers using the Dojo framework an easy and convenient way for allowing user-generated script content. This is made possible because the sandbox is intended to block access to sensitive DOM properties such as \textit{window}, \textit{document}, \textit{location}, as well as classic DOM traversal methods. The Dojo sandbox is therefore expected to be capable of keeping script execution limited to a particular HTML element and its children, prohibiting access to parent nodes in efforts to prevent information leakage and arbitrary script execution. The Dojo Sandbox is based on the principles formulated by AdSafe~\cite{crockford2008adsafe}. Finifter et al. covered the Dojo sandbox in their publication on capability leaks in seemingly secure 
JavaScript subset implementations~\cite{finifter2010preventing}. \\

    While several attack vectors against the Dojo sandbox were published and fixed in 2010, Magazinius raised an orchestrated comeback discussion on this topic in 2011, as he has published a novel bypass~\footnote{Magazinius, J. et al., \textit{List of sandboxes}, \url{http://sla.ckers.org/forum/read.php?26,35997,36336#msg-36336} (May 2011)}. It was quickly followed by three additional bypasses resulting from our research on the security of this implementation. The code in Listing~\ref{lst:dojo-secure-bypasses} demonstrates those bypasses. In defiance of expectations raised by public reporting, no fixes against these issues have been deployed so far and the bypasses can therefore be considered to be zero-day vulnerabilities. The bypasses base on techniques explained in detail in Section~\ref{subsubsec:4.3.3.escaping} and Section~\ref{subsubsec:6.2.3.prototyping}. To make matters worse, another bypass has been reported by Heyes short thereafter.

\begin{lstlisting}[captionpos=b,caption=Bypassing the Dojo Secure sandbox; Bypasses use obscured syntax, ``var obfuscation'' and prototype chaining,label=lst:dojo-secure-bypasses]
// Bypass by J. Magzinius
var window; delete window; alert(window); 

// Bypass by G. Heyes
1..\u0063\u006f\u006e\u0073\u0074\u0072\u0075\u0063
\u0074\u006f\u0072.\u0063\u006f\u006e\u0073\u0074
\u0072\u0075\u0063\u0074\u006f\u0072('alert("PWND!")')()

// Bypasses by M. Heiderich
var a=[];alert(a['__parent__']);

x=[]&&1['constructor']['constructor']('alert(window)')();

{_:[]['constructor']['constructor']('alert(window)')()};
\end{lstlisting}
    
    From a security point of view, the Dojo sandbox -- in the state we last tested it in -- should not be employed in projects handling sensitive data until the spotted security problems have been successfully resolved and an in-depth penetration test has taken place. The handling of Unicode escapes must be improved drastically, and the regular expressions checking against legitimate use for the \textit{[]} accessor/operator needs special attention and extensive improvements. Further, the sandbox handling of code following variable assignments is fundamentally broken. As code example in Listing~\ref{lst:dojo-secure-bypasses} shows, two of the bypasses utilize these assignment bugs to inject and execute arbitrary code. Measuring by the time necessary for finding and generalizing bypasses and gaining access to the global window object, JSReg seems several years ahead of the Dojo Sandbox in terms of security and robustness.

    \subsubsection{Web Workers}
    \label{subsubsec:4.10.3.web_workers}

    As specified by WHATWG and W3C, Web Workers bear a chance for interesting security implications delivered as a byproduct~\footnote{W3C, \textit{Web Workers}, \url{http://dev.w3.org/html5/workers/} (Dec 2011)}. Their main purpose is to enable a web application requiring several CPU performance consuming tasks to outsource these in Worker threads, significantly reducing the chance of interfering with the actual website's JavaScript business logic and thereby evade the risk of negatively influencing user experience. Workers are designed to compute background tasks, such as mathematical operations, inclusion of potentially slow and large resources, and resource-hungry graphics operations. Per specification, the Worker interface is capable of spawning OS-level threads. Given that nature, a Worker has no default access to any components of the DOM that are only available in a non-thread-safe environment. Most browsers allow creating a Worker by including its code via a static file/same domain resource 
following SOP restrictions discussed in Section~\ref{subsubsubsec:2.4.1.1.same_origin_policy}. Opera, however, enables creating Workers from data URIs, which can be problematic in an injection scenario. It allows an attacker to inject arbitrary worker code and thereby compromising a website's security. Similarly to local storage mechanisms, the window object, document, or any other relevant DOM node, cannot be accessed by a Worker thread. Google Chrome nevertheless implemented Web database support for workers in 2010. Most implementation also support \textit{SharedWorker} interfaces, giving several documents possibility to share a Worker applied with the same base URI~\footnote{MDN, \textit{SharedWorker}, \url{https://developer.mozilla.org/En/DOM/SharedWorker} (Dec 2011)}. Shared workers possess a slightly different API than the normal Workers and are not yet implemented across all browsers tested in our research.\\

    A Worker can retrieve its own location, request further script resources via \textit{importScripts} and send cookie headers while doing so. Note that those resources can be imported across domains. Worker is thus capable of gaining awareness of its own location, domain and authentication tokens, if they are sent via cookie headers. In 2009, Grey proposed Workers as a sandbox solution for the above mentioned motives. 
    Given the here-listed facts, it was not an unreasonable act~\footnote{Grey, E., \textit{JavaScript sandbox using Web Workers}, \url{http://ajaxian.com/archives/javascript-sandbox-using-web-workers}, (June 2009)}. Workers are capable of defining and receiving events, exchanging information with the hosting document via the \textit{postMessage} API, allowing interchange of string data. From late 2011 onwards, Google Chrome not only permits exchanging string data with the hosting domain but also facilitates structured cloning -- meaning the exchange of \textit{ArrayBuffer} objects and therefore complex data structures~\footnote{Bidelman, E., \textit{Transferable Objects: Lightning Fast!}, \url{http://updates.html5rocks.com/2011/12/Transferable-Objects-Lightning-Fast} (Dec 2011)}. Theriault discussed various security aspects of Workers in 2010, pinpointing a significant concern as to why Workers are not supposed to be a security tool or even sandbox~\footnote{Theriault, P., \textit{http://www.stratsec.net/
getattachment/5cd9dfdd-227e-4bef-9b2f-87fd836bbdd0/\\
stratsec---HITB-2010---Can-You-Trust-Your-Workers.pdf} (2010)}: 
    Any Worker implementation lets the \textit{XMLHttpRequest} object to be used and requests same domain data while sending authentication tokens and cookies. An attacker can execute code inside a worker in order to access any data exposed by the attacked application. Generating similar information leak or even CSRF attack surface as with a classic XSS attack is hence achievable. Hasegawa discovered an extra implementation fault in Firefox. When combining a Worker fetching cross-domain data via \textit{importScripts} with the E4X capabilities of Gecko-based browsers, a full stack cross-domain exploit can be accomplished~\footnote{Hasegawa, Y., \textit{Combining "importScripts" of WebWorker with E4X causes information disclosure}, \url{https://bugzilla.mozilla.org/show_bug.cgi?id=568148} (May 2010)}.\\

    For many reasons Workers are not to be seen as a DOM sandbox of any kind, despite the fact that by design a decent level of isolation between hosting page and Worker code is in place. The fact that \textit{XMLHttpRequest} instance calls can be issued from within Workers alone, invalidates their quality as a sandbox.

    \subsubsection{Rhino and LiveConnect}
    \label{subsubsec:4.10.4.rhino_and_live_connect}

    In Section~\ref{subsubsubsec:2.4.3.2.java_plugin_security}, we have elaborated on browser plug-in security and the implications of allowing the Java plug-in to create an off-the-record DOM object permitting direct execution of Java applet code by the JavaScript engine. This strange and rarely used interface has resulted numerous security vulnerabilities in the past. Nevertheless, the LiveConnect and Java applet functionality in general was found to be potentially useful for sand-boxing purposes for one particular reason. The Java runtime engine implements a very own JavaScript engine based on the Rhino JavaScript interpreter. This script engine can be instantiated inside an applet, which basically means the exact operation can also take place within LiveConnect code. In essence, JavaScript can launch Java code that \textit{then} can launch another JavaScript engine to launch further JavaScript code. This happens completely outside the originating DOM, since it is running in a completely different engine. 
This indicates a perfect sandbox: fully isolated and incapable to access the hosting DOM, because at least three layers would have needed to be crossed. No access to the global \textit{window} object, \textit{document} or even the \textit{XMLHttpRequest} interface is granted in this execution context -- the Rhino engine simply does not know or expose those objects.\\

    Unfortunately, our research showed that the multi-layer separation and isolation give no guarantees for providing a valid sand-boxing environment that meet all of the requirements. We have found several bypasses allowing an attacker to access properties of the hosting DOM from within the Rhino-executed JavaScript code. Upon uncovering the second working exploit, it was decided to host a challenge for other researchers to look for similar bypasses working on a testbed we provided. The challenge required the contestants to use Firefox and install either Java 6 in latest version or the most recent Java 7 beta~\footnote{Heiderich, M. et al., \textit{So you think you can dance?}, \url{http://kotowicz.net/java/java.html} (Nov 2011)}. At the same time, a Java-based exploit was published by Schierl, who used  similar technique to obtain a Java security manager restriction bypass and thereby full code execution privileges on affected  systems~\footnote{Schierl, M., \textit{Oracle Java Applet Rhino Script Engine 
Remote Code Execution}, \url{http://schierlm.users.sourceforge.net/CVE-2011-3544.html} (Oct 2011)}. The code in Listing~\ref{lst:java-rhino-testbed} demonstrates the testbed we set up for our participants. The coveted task was to prove  sandbox broken. Solving the challenge equalled getting access to a secret base64 encoded value, available exclusively in the hosting DOM.

\begin{lstlisting}[captionpos=b,caption=Java Rhinos XSS challenge testbed; Two given injection points were made available for the contestants -- one using bindings,label=lst:java-rhino-testbed]
<script>
if(typeof Packages === 'undefined'){
  alert('Java plug-in is missing - cannot access `Packages`')
}
function go() {
  var y=new Packages.com.sun.script.javascript.RhinoScriptEngine()
  var b = y.createBindings();
  b.put('$', y.eval(_.value));
  y.eval(__.value, b);
}
</script>
\end{lstlisting}

   Quickly after the challenge was published, the first submissions were sent in by the contestants. The key to solving the challenge and thereby breaking the hypothetical Java and Rhino-based JavaScript sandbox was to realize a surprising implementation detail. Once the sand-boxed JavaScript code itself creates a LiveConnect object via the Packages interface, the access to the DOM is made available again. An attacker could for instance create a \textit{JSObject} instance via \texttt{Packages.netscape.javascript.JSObject}, thereby gaining access to the \textit{getWindow} method and call it with a \textit{null} parameter~\footnote{Oracle Inc., \textit{Java-to-Javascript Communication}, \url{http://docs.oracle.com/javase/6/docs/technotes/guides/plugin/developer_guide/java_js.html} (Dec 2011)}. While the method is supposed to receive a reference to its applet context, in LiveConnect passing a null parameter or simply an unreferenced variable, the JRE will mistakenly take it as a valid call and return a 
reference to the hosting DOM in reaction. This means that for one, an attacker has full and unlimited access to the DOM again, and secondly, the sandbox is effectively broken. Several other submissions in later phases of the challenge did not even have to utilize the \textit{JSObject} instance anymore, but simply abused a novel Java 7 SOP weakness and called an internal Java Swing dialog. Hippert provided several bypassing vectors working on Max OSX as well -- where a slightly different JVM is being used. This was followed by accessing a hidden key in the hosting DOM, performing a base64 decoding and echoing the secret value necessary to prove the sandbox was broken and the challenge was cracked. The code in Listing~\ref{lst:java-rhino-submissions} displays some of the most interesting submissions from the contestants. The outcome of the challenge and our preceding research was clear: despite its high isolation level, the Rhino-JavaScript engine is not suitable for DOM sand-boxing.

\begin{lstlisting}[captionpos=b,caption=Java Rhinos XSS challenge submissions,label=lst:java-rhino-submissions]
// submitted by @einaros
(w=Packages.netscape.javascript.JSObject.getWindow(null))
  .eval('alert(\"'+w.getMember('document').getMember('secret')+'\")') 

//submitted by @irsdl
myJSObject=new Packages.netscape.javascript.JSObject.getWindow($);println(
  myJSObject.getMember("document").getMember("secret"));

//submitted by "akormushin"
var inputStream = new java.io.BufferedReader(new java.io.InputStreamReader(
  new java.net.URL("http://kotowicz.net/java/java.html").openStream()));
var inputLine = ""; var inputStringBuilder = new java.lang.StringBuilder();
while ((inputLine = inputStream.readLine()) != null){inputStringBuilder.append(inputLine);}
var match = /document\.secret=atob\(\'(.*)\'\);/i.exec(inputStringBuilder.toString());
javax.swing.JOptionPane.showMessageDialog(null, new java.lang.String(
  javax.xml.bind.DatatypeConverter.parseBase64Binary(match[1])))
\end{lstlisting}

  \subsection{Roundup and Conclusion}
  \label{subsection:4.11.roundup_and_conclusion}

  Modern and complex web application have a wide array of libraries and tools at their disposal that grant reliable security from script and code injection attacks. Most of the discussed tools can boast about being well-documented and easy-to-install, on top of delivering good and thorough protection against classic XSS attacks. Popular run-times and environments are fully covered with similarly well-maintained software, for example PHP developers can use the HTMLPurifier among a plenitude of other libraries and native functions, SafeHTML and AntiSamy cover .NET, while ASP and Java applications and multiple browsers are supplied with well-maintained XSS filters and protection assets. Furthermore, web and script sandboxes are on the rise. We have seen numerous approaches and various attempts to hinder scripts from accessing sensitive properties. Sadly, XSS vulnerabilities and attacks are gaining momentum and have become one of the most problematic aspects of web application and browser security~\
footnote{OWASP, \textit{Top 10 2010-Main}, \url{https://www.owasp.org/index.php/Top_10_2010-Main} (Apr 2010)}.\\

  What all of the introduced tools have in common, is an ordinary flaw: they all analyze and sanitize the incoming code on a layer where it does not actually execute. The server-side solutions receive a string, tokenize it, analyze the nodes and node values. Afterwards, they decide on how to proceed with manipulating the data so as to make sure no active code fragments will remain for later processing or display of that data. In case one of the layers involved in the receiving process will either ignore, oversee or even manipulate fragments of the analyzed and sanitized code, the protection might be prone to being compromised, or alternatively, all of the other layers involved must become aware of this potential problem and mismatches. We will dedicate several sections, starting with Section~\ref{sec:5.attacking_existing_mitigation_approaches}, to this particular problem. Upon evaluating the actual protection performance of the described and discussed filter and security libraries, we will introduce bypasses 
and design flaws. As our ultimate contribution, we will propose a novel way of approaching XSS attacks in Section~\ref{sec:6.rethinking_client_side_web_security} that can solely be based on a single JavaScript file deployed on a website otherwise unprotected against XSS and scripting web attacks. Our proposal does not require browsers to significantly change behavior or web applications to be modified by their developers. As stated in Section~\ref{subsec:1.4.contribution_and_outlook} we will exclusively use standardized scripting techniques and discuss an approach that coexists in harmony with recent and upcoming changes to the ES6 specification draft, covered in Section~\ref{sec:future_work}.\\

  In the end, defending web applications and their users from simple and well documented standard attacks has never been a great challenge. 
  The attacks that are not commonly known or undocumented are considered to be true threats, as they are not the ``known bad''. The following sections will outline those attacks and discuss them in connection to the aforementioned mitigation techniques. Understanding their anatomy, operational details and structure, will lead us to grasping the urgent need for a novel defense approach.  

\pagebreak